{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AvCsKqwRPHVP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\envs\\pytorch_audio\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import soundfile as sf\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EWWl4P7POsd"
      },
      "outputs": [],
      "source": [
        "# Instead of downloading the entirety of the 200GB dataset, we are going to stream the dataset! This uses hugging face and AWS\n",
        "dataset = load_dataset('simon3000/genshin-voice', split='train', streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIf-k_ASUQRV"
      },
      "outputs": [],
      "source": [
        "# Filter dataset to relevant rows\n",
        "def filter_dataset(dataset):\n",
        "    for entry in dataset:\n",
        "        # Only keep rows that are not NPCs or that are in the \"English Language\"\n",
        "        if 'vo_npc' not in entry['inGameFilename'].lower() and entry['language'] == \"English(US)\":\n",
        "            yield entry\n",
        "\n",
        "filtered_dataset = filter_dataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "UqCH1I2KPsj5"
      },
      "outputs": [],
      "source": [
        "# Initialize a default dictionary for character counts\n",
        "character_counts = defaultdict(int)\n",
        "\n",
        "# Goes through each row of the filtered dataset\n",
        "for voice in tqdm(filtered_dataset, desc=\"Processing voices\", unit=\"file\"):\n",
        "    # identify the character for the row\n",
        "    speaker = voice['speaker']\n",
        "\n",
        "    # We only keep 100 wav files for each character\n",
        "    if character_counts[speaker] < 100:\n",
        "        # create a character folder if needed\n",
        "        character_folder = os.path.join(\"characters\", speaker)\n",
        "        os.makedirs(character_folder, exist_ok=True)\n",
        "\n",
        "        audio_path = os.path.join(character_folder, f'{character_counts[speaker]}_audio.wav')\n",
        "\n",
        "        # create the audio file in the appropriate character folder\n",
        "        sf.write(audio_path, voice['audio']['array'], voice['audio']['sampling_rate'])\n",
        "\n",
        "        # add one to the number of files a character has \n",
        "        character_counts[speaker] += 1\n",
        "\n",
        "        print(f'{character_counts[speaker]} audio files for {speaker} done')\n",
        "\n",
        "    if character_counts[speaker] == 100:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP75u8o4jhc1"
      },
      "outputs": [],
      "source": [
        "directory = '/content/characters'\n",
        "\n",
        "items = os.listdir(directory)\n",
        "\n",
        "directories = [item for item in items if os.path.isdir(os.path.join(directory, item))]\n",
        "sorted(directories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFuUPp0e9jxg"
      },
      "outputs": [],
      "source": [
        "playable = [\n",
        "    \"Albedo\",\n",
        "    \"Alhaitham\",\n",
        "    \"Aloy\",\n",
        "    \"Amber\",\n",
        "    \"Arataki Itto\",\n",
        "    \"Baizhu\",\n",
        "    \"Barbara\",\n",
        "    \"Beidou\",\n",
        "    \"Bennett\",\n",
        "    \"Candace\",\n",
        "    \"Chongyun\",\n",
        "    \"Collei\",\n",
        "    \"Cyno\",\n",
        "    \"Dehya\",\n",
        "    \"Diluc\",\n",
        "    \"Diona\",\n",
        "    \"Dori\",\n",
        "    \"Eula\",\n",
        "    \"Faruzan\",\n",
        "    \"Fischl\",\n",
        "    \"Freminet\",\n",
        "    \"Ganyu\",\n",
        "    \"Gorou\",\n",
        "    \"Hu Tao\",\n",
        "    \"Jean\",\n",
        "    \"Kaedehara Kazuha\",\n",
        "    \"Kaeya\",\n",
        "    \"Kamisato Ayaka\",\n",
        "    \"Kamisato Ayato\",\n",
        "    \"Kaveh\",\n",
        "    \"Keqing\",\n",
        "    \"Kirara\",\n",
        "    \"Klee\",\n",
        "    \"Kujou Sara\",\n",
        "    \"Kuki Shinobu\",\n",
        "    \"Layla\",\n",
        "    \"Lisa\",\n",
        "    \"Lynette\",\n",
        "    \"Lyney\",\n",
        "    \"Mika\",\n",
        "    \"Mona\",\n",
        "    \"Nahida\",\n",
        "    \"Nilou\",\n",
        "    \"Ningguang\",\n",
        "    \"Noelle\",\n",
        "    \"Paimon\",\n",
        "    \"Qiqi\",\n",
        "    \"Raiden Shogun\",\n",
        "    \"Razor\",\n",
        "    \"Rosaria\",\n",
        "    \"Sangonomiya Kokomi\",\n",
        "    \"Sayu\",\n",
        "    \"Shenhe\",\n",
        "    \"Shikanoin Heizou\",\n",
        "    \"Sucrose\",\n",
        "    \"Tartaglia (Childe)\",\n",
        "    \"Thoma\",\n",
        "    \"Tighnari\",\n",
        "    \"Traveler (Anemo)\",\n",
        "    \"Traveler (Geo)\",\n",
        "    \"Traveler (Electro)\",\n",
        "    \"Traveler (Dendro)\",\n",
        "    \"Venti\",\n",
        "    \"Wanderer\",\n",
        "    \"Xiangling\",\n",
        "    \"Xiao\",\n",
        "    \"Xingqiu\",\n",
        "    \"Xinyan\",\n",
        "    \"Yae Miko\",\n",
        "    \"Yanfei\",\n",
        "    \"Yaoyao\",\n",
        "    \"Yelan\",\n",
        "    \"Yoimiya\",\n",
        "    \"Yun Jin\",\n",
        "    \"Zhongli\",\n",
        "    \"Charlotte\",\n",
        "    \"Navia\",\n",
        "    \"Clorinde\",\n",
        "    \"Wriothesley\",\n",
        "    \"Neuvillette\",\n",
        "    \"Furina\",\n",
        "    \"Freminet\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVL8Pv-L-0ye"
      },
      "outputs": [],
      "source": [
        "lst = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0psOYW_9lR-"
      },
      "outputs": [],
      "source": [
        "for i in directories:\n",
        "  for j in playable:\n",
        "    if i.lower() in j.lower():\n",
        "      lst.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LwQFYV3_E8T"
      },
      "outputs": [],
      "source": [
        "# a list of valid characters for our model to predict (aka the playable ones)\n",
        "directory_lst = list(set(lst))\n",
        "len(lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7gY_OmYF_0Z2"
      },
      "outputs": [],
      "source": [
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzUgXnhK_Hlr"
      },
      "outputs": [],
      "source": [
        "content_dir = '/content/characters'\n",
        "all_directories = [d for d in os.listdir(content_dir) if os.path.isdir(os.path.join(content_dir, d))]\n",
        "directories_to_delete = [d for d in all_directories if d not in directory_lst]\n",
        "# remove all directories that are not playable characters\n",
        "for dir_name in directories_to_delete:\n",
        "    dir_path = os.path.join(content_dir, dir_name)\n",
        "    shutil.rmtree(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vgpoqou_AFVT"
      },
      "outputs": [],
      "source": [
        "# get the total size of the character directory\n",
        "def get_directory_size(directory):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(directory):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            if not os.path.islink(fp):\n",
        "                total_size += os.path.getsize(fp)\n",
        "    return total_size\n",
        "\n",
        "all_directories = [d for d in os.listdir(content_dir) if os.path.isdir(os.path.join(content_dir, d))]\n",
        "\n",
        "total_size = 0\n",
        "for dir_name in all_directories:\n",
        "    dir_path = os.path.join(content_dir, dir_name)\n",
        "    size = get_directory_size(dir_path)\n",
        "    total_size += size\n",
        "    print(f\"Directory: {dir_path} - Size: {size} bytes\")\n",
        "\n",
        "print(f\"Total size of all directories in content folder: {total_size} bytes ({total_size / (1024**2):.2f} MB)\")\n",
        "# We end up with a size of 5GB which is significantly smaller than the 200GB dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-3NUYuIAmBz"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "folder_path = '/content/characters'\n",
        "\n",
        "zip_file = '/content/characters.zip'\n",
        "\n",
        "shutil.make_archive('/content/characters', 'zip', folder_path)\n",
        "\n",
        "files.download(zip_file)\n",
        "#download the entire zip folder of our characters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbgOWO-RGtff"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
