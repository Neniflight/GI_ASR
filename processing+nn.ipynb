{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddu\\anaconda3\\envs\\pytorch_audio\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import torch \n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are using mac, pip install sox\n",
    "# otherwise, pip install PySoundFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soundfile']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchaudio.list_audio_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddu\\anaconda3\\envs\\pytorch_audio\\Lib\\site-packages\\transformers\\configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_voice_embeddings(audio_file):\n",
    "    waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "        sample_rate = 16000\n",
    "\n",
    "    waveform = F.normalize(waveform)\n",
    "\n",
    "    if waveform.ndimension() == 2:\n",
    "        waveform = waveform.squeeze(0)\n",
    "        \n",
    "    inputs = processor(waveform, sampling_rate=sample_rate, return_tensors=\"pt\", padding=True)\n",
    "    input_values = inputs['input_values'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(input_values).last_hidden_state\n",
    "    \n",
    "    voice_embedding = torch.mean(embeddings, dim=1).squeeze().cpu().numpy()\n",
    "    return voice_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddu\\anaconda3\\envs\\pytorch_audio\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "c:\\Users\\siddu\\anaconda3\\envs\\pytorch_audio\\Lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:958: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.0357823 ,  0.05431148,  0.34946448,  0.1121379 ,  0.27968332,\n",
       "       -0.2737367 ,  0.07846474, -0.20731293, -0.17776124, -0.12317158,\n",
       "       -0.04602772,  0.5656206 ,  0.23186235,  0.16278815,  0.18053694,\n",
       "       -0.04977191,  0.27083847, -0.00630548, -0.128712  , -0.6694658 ,\n",
       "       -0.08326234, -0.09285967,  0.0740937 ,  0.42214197,  0.41874737,\n",
       "       -0.12893163,  0.12028143, -0.22105113, -0.13587776,  0.12663187,\n",
       "       -0.30808446, -0.04941976, -0.51878434,  0.08194198, -0.00690099,\n",
       "        0.17276925, -0.16830753,  0.09708958,  0.12068896, -0.13339195,\n",
       "       -0.24577633,  0.04646227, -0.1270652 , -0.09494544, -0.7655716 ,\n",
       "       -0.35917178, -0.22518249,  0.14477172,  0.05852978, -0.16208558,\n",
       "       -0.02091702,  0.36183825,  0.34151512,  0.08962654,  0.28449824,\n",
       "       -0.02282706,  0.13232182,  0.02939306,  0.08540127, -0.09387352,\n",
       "       -0.0825976 ,  0.04466575, -0.08380934,  0.10722651, -0.22208484,\n",
       "       -0.03650331, -0.11089969, -0.3184559 , -0.00740583,  0.05636467,\n",
       "       -0.08498581, -0.04308351,  0.23554444,  0.197674  ,  0.03772841,\n",
       "        0.3909225 ,  0.46221572, -0.08176914, -0.22400592, -0.07861669,\n",
       "        0.36394858,  0.01950186,  0.0663503 ,  0.0152203 ,  0.02940618,\n",
       "        0.25710374,  0.00917298, -0.08110315, -0.19867726, -0.06127729,\n",
       "       -0.45879453, -0.20217481, -0.04298401, -0.10401843, -0.26815864,\n",
       "        0.0734646 ,  0.359105  , -0.12988767, -0.01253591, -0.07205611,\n",
       "       -0.18973911,  0.07793266, -0.2301048 , -0.17809232,  0.04660702,\n",
       "        0.19887023,  0.17428498,  0.01858989, -0.09217956,  0.19808827,\n",
       "       -0.14349985,  0.283286  ,  0.18468493, -0.03056207,  0.02299664,\n",
       "        0.06457022, -0.08865048, -0.32915097, -0.00770862, -0.23466209,\n",
       "       -0.44211587, -0.07188584,  0.14933234, -0.03100816, -0.35659942,\n",
       "        0.04385436,  0.38310838, -0.10224784,  0.45102704, -0.39312804,\n",
       "        0.28516206,  0.13895361, -0.19280079, -0.06546475, -0.15804848,\n",
       "        0.31671157, -0.05249748,  0.09174465,  0.16105436,  0.16518188,\n",
       "        0.08333831, -0.19086999,  0.03157751,  0.05382008, -0.10387035,\n",
       "       -0.07484018, -0.7099062 ,  0.32593635,  0.05409189,  0.3794048 ,\n",
       "        0.08588918,  0.34667337, -0.08370478,  0.32200652,  0.09652185,\n",
       "       -0.230135  ,  0.0139417 , -0.05315118, -0.12590747, -0.01792127,\n",
       "        0.06627893, -0.01744857,  0.07998985, -0.09751286, -0.1022224 ,\n",
       "       -0.16402294,  0.40061626,  0.41273624,  0.30477408, -0.35027292,\n",
       "        0.06280823,  0.08101672, -0.16234058,  0.02502991, -0.11511536,\n",
       "        0.50154257, -0.41949263, -0.09952331,  0.03769935, -0.09622796,\n",
       "       -0.1186219 ,  0.050421  ,  0.02251857,  0.04672533, -0.31376475,\n",
       "       -0.0623465 ,  0.10855311,  0.31487218, -0.07192974, -0.25684625,\n",
       "        0.45539686,  0.10824056, -0.04299505,  0.06730159, -0.03440941,\n",
       "        0.1294689 ,  0.05843283,  0.23985627, -0.130871  ,  0.09859975,\n",
       "        0.12606019, -0.03727792, -0.70112073, -0.07593658,  0.05524773,\n",
       "       -0.3409373 ,  0.00410857,  0.0220413 ,  0.05015866,  0.19809386,\n",
       "        0.3108789 , -0.19932006, -0.12629609, -0.24871503, -0.35608083,\n",
       "        0.02175997, -0.3313438 , -0.275154  , -0.05166722,  0.06185429,\n",
       "        0.05836226, -0.23086151,  0.04940799, -0.06533926,  0.20944156,\n",
       "        0.2972079 ,  0.12943843,  0.21693522,  0.04038531,  0.06756648,\n",
       "        0.00463986,  0.24224855, -0.04199639,  0.04201405,  0.21214762,\n",
       "        0.11232399, -0.02269752,  0.0820228 ,  0.07330783, -0.18268962,\n",
       "       -0.60415953, -0.03091956,  0.07758621,  0.1545475 ,  0.35674098,\n",
       "        0.02847295, -0.04952255,  0.02577821,  0.30997425,  0.06419292,\n",
       "        0.06459051, -0.04106896, -0.06052625,  0.1942451 ,  0.14920156,\n",
       "       -0.21515734,  0.2088747 ,  0.13847226,  0.22526146,  0.01823668,\n",
       "       -0.08707663, -0.20211272, -0.35154635,  0.23530836, -0.7694813 ,\n",
       "        0.36413035, -0.02103421,  0.04248397,  0.10296873,  0.10046362,\n",
       "        0.12913628,  0.27009144,  0.02502444,  0.10651689,  0.10786928,\n",
       "        0.4666976 ,  0.02101362, -0.08809946,  0.22035132, -0.06920399,\n",
       "       -0.10090793,  0.26438594, -0.05858916,  0.09311346,  0.24100679,\n",
       "        0.0752032 ,  0.03053693,  0.01866949,  0.10579345, -0.33486864,\n",
       "       -0.32482383,  0.37025684, -0.2355739 ,  0.18063371, -0.25633234,\n",
       "       -0.08448342,  0.03403382, -0.07285906, -0.14066294, -0.03005095,\n",
       "       -0.064725  , -0.37206796,  0.04148754,  0.0901393 , -0.02503449,\n",
       "       -0.28476116,  0.3541734 ,  0.28658694,  0.0794819 ,  0.13264617,\n",
       "        0.46644807,  0.69955057, -0.31799138,  0.2782658 , -0.06606326,\n",
       "        0.04935717,  0.07823778, -0.14025325, -0.21238063,  0.09573888,\n",
       "       -0.32296926,  0.03137997,  0.4084865 ,  0.36439416, -0.03278711,\n",
       "       -0.27654904,  0.45186633, -0.18877576,  0.11238866,  0.14079964,\n",
       "        0.1984619 ,  0.37177306, -0.0811567 , -0.18234101, -0.12515202,\n",
       "       -0.1094722 , -0.28398484,  0.03775955, -0.2155305 , -0.17521259,\n",
       "        0.3515743 ,  0.18998681,  0.3872542 , -0.1626316 , -0.43806052,\n",
       "        0.13648239,  0.01498755, -0.45230395,  0.27447662, -0.12603429,\n",
       "        0.02026129, -0.17035623,  0.21720754,  0.02962867,  0.15398158,\n",
       "        0.2808301 , -0.04692076,  0.06381936,  0.04777265, -0.06269137,\n",
       "        0.10039008, -0.21557586,  0.03570878, -0.19809164, -0.02649662,\n",
       "       -0.476586  , -0.00175573, -0.20854872, -0.2687731 , -0.10767996,\n",
       "       -0.12147908, -0.5576344 ,  0.04822334,  0.10683534, -0.33298507,\n",
       "       -0.17840798,  0.21214618, -0.26661247,  0.19611286, -0.01674903,\n",
       "       -0.1384096 , -0.01429708, -0.08767153,  0.48422512, -0.8876226 ,\n",
       "        0.19448005, -0.5454931 ,  0.13135621, -0.04271249,  0.3637743 ,\n",
       "        0.1813851 ,  0.09951656, -0.38655818, -0.46825927,  0.18835875,\n",
       "        0.35040265, -0.16812092, -0.0397316 ,  0.63742596, -0.2218917 ,\n",
       "        0.06442774,  0.17900573, -0.05060111, -0.31859916, -0.10660189,\n",
       "        0.14922796,  0.2999129 , -0.04811942, -0.08650801, -0.37380636,\n",
       "       -0.04073128,  0.40421933, -0.05331337, -0.0483537 ,  0.15538692,\n",
       "       -0.14459419,  0.05372081, -0.17920327,  0.37990752, -0.01526117,\n",
       "        0.10102119, -0.12184402, -0.20400937, -0.12316999, -0.1652987 ,\n",
       "        0.12045965, -0.07142762,  0.03175876,  0.07969146, -0.05559186,\n",
       "        0.0958842 ,  0.21551521,  0.26212156,  0.11067905, -0.09704334,\n",
       "       -0.06942125,  0.03519256,  0.253865  ,  0.17349553, -0.6784552 ,\n",
       "       -0.09782817,  0.14473675,  0.32095426, -0.06813085,  0.02276253,\n",
       "       -0.1681982 , -0.19915053, -0.03284484, -0.13436738, -0.02898732,\n",
       "       -0.22171079, -0.04586086, -0.22827747, -0.20198384, -0.02909561,\n",
       "        0.04662374,  0.11430542,  0.12566577,  0.16497906,  0.06429458,\n",
       "       -0.39799598, -0.00440332, -0.10309674, -0.20441985, -0.03137548,\n",
       "        0.0735452 ,  0.11713926,  0.25661844, -0.07261651, -0.2668149 ,\n",
       "       -0.08695777, -0.09184459,  0.08591855,  0.0292479 ,  0.02719404,\n",
       "       -0.01467063,  0.08488659,  0.1350998 , -0.44941393, -0.13706005,\n",
       "       -1.0382975 ,  0.05818179, -0.13750245, -0.16149378, -0.03371488,\n",
       "        0.06584176,  0.00962912, -0.05071449,  0.05584514,  0.395154  ,\n",
       "       -0.11953382,  0.09294847,  0.03162346, -0.01121349, -0.26724273,\n",
       "        0.16610049,  0.07358076, -0.29256785, -0.01530011,  0.00681677,\n",
       "       -0.26609686,  0.19720611,  0.04240361, -0.09253235, -0.2540809 ,\n",
       "       -0.28941876,  0.04873054,  0.36538166,  0.15430784, -0.02450496,\n",
       "        0.125507  ,  0.11127542,  0.16729085, -0.10293638, -0.02921004,\n",
       "        0.16191618,  0.5442581 ,  0.13070491,  0.30852327,  0.2874133 ,\n",
       "       -0.21958879,  0.10402507,  0.16086529,  0.00986595, -0.3286924 ,\n",
       "       -0.24137959, -0.09630053, -0.24731116, -0.2472295 ,  0.5559662 ,\n",
       "       -0.11371861,  0.14030248, -0.07913482, -0.1163886 ,  0.48013324,\n",
       "        0.14775826,  0.24085139,  0.00751323,  0.4062062 ,  0.18370174,\n",
       "       -0.05886802, -0.21318597, -0.17818633, -0.15627192, -0.10036435,\n",
       "       -0.24995786,  0.11848483,  0.33890426,  0.01715666,  0.08027006,\n",
       "        0.63654506,  0.25845602,  0.02677631, -0.06252275,  0.01379235,\n",
       "        0.38805002,  0.20280421, -0.05668727,  0.17915192,  0.10436903,\n",
       "        0.02384503,  0.11779325, -0.03926489, -0.06871327, -0.24881111,\n",
       "        0.10273326,  0.0300264 ,  0.10868005,  0.05936508,  0.16607827,\n",
       "        0.35792434, -0.4369947 ,  0.15615074, -0.06295186,  0.5337686 ,\n",
       "       -0.09933347,  0.6417204 , -0.402072  ,  0.14229953,  0.25491223,\n",
       "       -0.06805626, -0.4068553 , -0.11176166,  0.03668737,  0.17446887,\n",
       "        0.00238509, -0.09006646, -0.09812452,  0.02784969,  0.05162286,\n",
       "       -0.00545412,  0.18900238,  0.00170586,  0.1877581 , -0.10683211,\n",
       "        0.31670132, -0.14483951, -0.13638683, -0.1362557 ,  0.23564678,\n",
       "       -0.18334803, -0.35654855,  0.13754408, -0.00759589, -0.30593643,\n",
       "        0.14424424, -0.19148375,  0.44056138,  0.0067754 , -0.34097192,\n",
       "        0.03230766, -0.26018614, -0.10543276, -0.32387283,  0.3088561 ,\n",
       "       -0.1972667 , -0.01999336,  0.10282565,  0.35333675, -0.30415735,\n",
       "       -0.12719697, -0.07189634,  0.20013037,  0.05225652,  0.13556556,\n",
       "       -0.14990276, -0.12901406, -0.26771557, -0.03197546,  0.14531828,\n",
       "       -0.14476006, -0.18484   ,  0.31134135,  0.17719892, -0.14484042,\n",
       "        0.2551315 ,  0.17217216, -0.41417953, -0.67479074, -0.07205287,\n",
       "       -0.13450769, -0.2836244 , -0.13858661,  0.04665616,  0.1605366 ,\n",
       "       -0.05595489, -0.30255505, -0.40470293, -0.35419118, -0.04490163,\n",
       "        0.38184512, -0.02911622,  0.01252372,  0.03908987,  0.09515739,\n",
       "       -0.06372763, -0.1663459 , -0.26165178, -0.35809293, -0.05798095,\n",
       "        0.3150217 ,  0.14424378, -0.3211646 ,  0.15080182,  0.03636617,\n",
       "       -0.28157207,  0.06499233, -0.15741639, -0.17270282, -0.07730906,\n",
       "       -0.30235302, -0.222093  , -0.17950323,  0.06610452,  0.02377024,\n",
       "        0.22358243,  0.22824812, -0.03131108,  0.17205681, -0.05031184,\n",
       "        0.15006898,  0.10557695,  0.15997212,  0.2978474 ,  0.1806209 ,\n",
       "        0.19300105, -0.09420067,  0.5553574 ,  0.18561128,  0.4043128 ,\n",
       "        0.06054199,  0.40718955, -0.13614671, -0.34184217, -0.0270271 ,\n",
       "        0.09287675, -0.08368289, -0.09532512,  0.08245995,  0.343955  ,\n",
       "       -0.41489518, -0.05797259, -0.04731749, -0.14410765, -0.23444071,\n",
       "        0.19829877,  0.12224084, -0.07264255, -0.11233916,  0.06179009,\n",
       "       -0.02097045, -0.04585262,  0.00946598, -0.07992704,  0.08016025,\n",
       "        0.27353373,  0.2531163 ,  0.09954156,  0.19343603,  0.10446788,\n",
       "       -0.23723103, -0.02870312, -0.01166745,  0.36138463,  0.13218747,\n",
       "       -0.02524883, -0.12866668, -0.33876455, -0.11675606, -0.15079108,\n",
       "       -0.05096269, -0.02772348,  0.06994557,  0.01869471, -0.14960182,\n",
       "        0.11809836,  0.09996094,  0.02212174, -0.01972846,  0.32772228,\n",
       "       -0.31799248, -0.22731824, -0.4404599 , -0.20092891, -0.05040451,\n",
       "       -0.38712317, -0.1722363 , -0.2787043 , -0.11485403, -0.2630299 ,\n",
       "       -0.32463866,  0.06289823, -0.06006688, -0.03378553,  0.23892091,\n",
       "        0.10535901, -0.00740602, -0.18652986, -0.10744549,  0.2007735 ,\n",
       "       -0.01962421,  0.04353926, -0.3654607 ,  0.00152216, -0.13590622,\n",
       "        0.12432688,  0.33086905, -0.33729976], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_voice_embeddings(\"characters/Albedo/79_audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"characters\"\n",
    "embeddings = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Albedo',\n",
       " 'Alhaitham',\n",
       " 'Aloy',\n",
       " 'Amber',\n",
       " 'Arataki Itto',\n",
       " 'Baizhu',\n",
       " 'Barbara',\n",
       " 'Beidou',\n",
       " 'Bennett',\n",
       " 'Candace',\n",
       " 'Charlotte',\n",
       " 'Childe',\n",
       " 'Chongyun',\n",
       " 'Clorinde',\n",
       " 'Collei',\n",
       " 'Cyno',\n",
       " 'Dehya',\n",
       " 'Diluc',\n",
       " 'Diona',\n",
       " 'Dori',\n",
       " 'Ei',\n",
       " 'Eula',\n",
       " 'Faruzan',\n",
       " 'Fischl',\n",
       " 'Freminet',\n",
       " 'Furina',\n",
       " 'Ganyu',\n",
       " 'Gorou',\n",
       " 'Hu Tao',\n",
       " 'Jean',\n",
       " 'Kaede',\n",
       " 'Kaedehara Kazuha',\n",
       " 'Kaeya',\n",
       " 'Kamisato Ayaka',\n",
       " 'Kamisato Ayato',\n",
       " 'Kaveh',\n",
       " 'Kazuha',\n",
       " 'Keqing',\n",
       " 'Kirara',\n",
       " 'Klee',\n",
       " 'Kujou Sara',\n",
       " 'Kuki Shinobu',\n",
       " 'Layla',\n",
       " 'Lisa',\n",
       " 'Lynette',\n",
       " 'Lyney',\n",
       " 'Mika',\n",
       " 'Mona',\n",
       " 'Nahida',\n",
       " 'Navia',\n",
       " 'Neuvillette',\n",
       " 'Nilou',\n",
       " 'Ningguang',\n",
       " 'Noelle',\n",
       " 'Paimon',\n",
       " 'Qiqi',\n",
       " 'Raiden Shogun',\n",
       " 'Razor',\n",
       " 'Rosaria',\n",
       " 'Sangonomiya Kokomi',\n",
       " 'Sayu',\n",
       " 'Shenhe',\n",
       " 'Shikanoin Heizou',\n",
       " 'Sucrose',\n",
       " 'Tartaglia',\n",
       " 'Thoma',\n",
       " 'Tighnari',\n",
       " 'Traveler',\n",
       " 'Venti',\n",
       " 'Wanderer',\n",
       " 'Wriothesley',\n",
       " 'Xiangling',\n",
       " 'Xiao',\n",
       " 'Xingqiu',\n",
       " 'Xinyan',\n",
       " 'Yae Miko',\n",
       " 'Yanfei',\n",
       " 'Yaoyao',\n",
       " 'Yelan',\n",
       " 'Yoimiya',\n",
       " 'Yun Jin',\n",
       " 'Zhongli']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_folder = [i for i in os.listdir(data_dir) if '.wav' not in i]\n",
    "char_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on Character: Albedo\n",
      "Currently on Character: Alhaitham\n",
      "Currently on Character: Aloy\n",
      "Currently on Character: Amber\n",
      "Currently on Character: Arataki Itto\n",
      "Currently on Character: Baizhu\n",
      "Currently on Character: Barbara\n",
      "Currently on Character: Beidou\n",
      "Currently on Character: Bennett\n",
      "Currently on Character: Candace\n",
      "Currently on Character: Charlotte\n",
      "Currently on Character: Childe\n",
      "Currently on Character: Chongyun\n",
      "Currently on Character: Clorinde\n",
      "Currently on Character: Collei\n",
      "Currently on Character: Cyno\n",
      "Currently on Character: Dehya\n",
      "Currently on Character: Diluc\n",
      "Currently on Character: Diona\n",
      "Currently on Character: Dori\n",
      "Currently on Character: Ei\n",
      "Currently on Character: Eula\n",
      "Currently on Character: Faruzan\n",
      "Currently on Character: Fischl\n",
      "Currently on Character: Freminet\n",
      "Currently on Character: Furina\n",
      "Currently on Character: Ganyu\n",
      "Currently on Character: Gorou\n",
      "Currently on Character: Hu Tao\n",
      "Currently on Character: Jean\n",
      "Currently on Character: Kaede\n",
      "Currently on Character: Kaedehara Kazuha\n",
      "Currently on Character: Kaeya\n",
      "Currently on Character: Kamisato Ayaka\n",
      "Currently on Character: Kamisato Ayato\n",
      "Currently on Character: Kaveh\n",
      "Currently on Character: Kazuha\n",
      "Currently on Character: Keqing\n",
      "Currently on Character: Kirara\n",
      "Currently on Character: Klee\n",
      "Currently on Character: Kujou Sara\n",
      "Currently on Character: Kuki Shinobu\n",
      "Currently on Character: Layla\n",
      "Currently on Character: Lisa\n",
      "Currently on Character: Lynette\n",
      "Currently on Character: Lyney\n",
      "Currently on Character: Mika\n",
      "Currently on Character: Mona\n",
      "Currently on Character: Nahida\n",
      "Currently on Character: Navia\n",
      "Currently on Character: Neuvillette\n",
      "Currently on Character: Nilou\n",
      "Currently on Character: Ningguang\n",
      "Currently on Character: Noelle\n",
      "Currently on Character: Paimon\n",
      "Currently on Character: Qiqi\n",
      "Currently on Character: Raiden Shogun\n",
      "Currently on Character: Razor\n",
      "Currently on Character: Rosaria\n",
      "Currently on Character: Sangonomiya Kokomi\n",
      "Currently on Character: Sayu\n",
      "Currently on Character: Shenhe\n",
      "Currently on Character: Shikanoin Heizou\n",
      "Currently on Character: Sucrose\n",
      "Currently on Character: Tartaglia\n",
      "Currently on Character: Thoma\n",
      "Currently on Character: Tighnari\n",
      "Currently on Character: Traveler\n",
      "Currently on Character: Venti\n",
      "Currently on Character: Wanderer\n",
      "Currently on Character: Wriothesley\n",
      "Currently on Character: Xiangling\n",
      "Currently on Character: Xiao\n",
      "Currently on Character: Xingqiu\n",
      "Currently on Character: Xinyan\n",
      "Currently on Character: Yae Miko\n",
      "Currently on Character: Yanfei\n",
      "Currently on Character: Yaoyao\n",
      "Currently on Character: Yelan\n",
      "Currently on Character: Yoimiya\n",
      "Currently on Character: Yun Jin\n",
      "Currently on Character: Zhongli\n"
     ]
    }
   ],
   "source": [
    "for character in char_folder:\n",
    "    character_dir = os.path.join(data_dir, character)\n",
    "    print(f\"Currently on Character: {character}\")\n",
    "    if os.path.isdir(character_dir):\n",
    "        for file_name in os.listdir(character_dir):\n",
    "            file_path = os.path.join(character_dir, file_name)\n",
    "            if file_path.endswith(\".wav\"):\n",
    "                embedding = extract_voice_embeddings(file_path)\n",
    "                embeddings.append(embedding)\n",
    "                labels.append(character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(embeddings)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(VoiceClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor([char_folder.index(label) for label in y_train], dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor([char_folder.index(label) for label in y_test], dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "num_classes = len(char_folder)\n",
    "vc_model = VoiceClassifier(input_dim, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vc_model.parameters(), lr=0.001)\n",
    "num_epochs = 100\n",
    "patience = 5\n",
    "best_loss = float('inf')\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 4.0622, Val Loss: 3.4643, Accuracy: 0.1836\n",
      "Epoch [2/100], Loss: 3.3211, Val Loss: 2.7833, Accuracy: 0.3579\n",
      "Epoch [3/100], Loss: 2.8910, Val Loss: 2.3713, Accuracy: 0.4285\n",
      "Epoch [4/100], Loss: 2.5927, Val Loss: 2.0397, Accuracy: 0.5097\n",
      "Epoch [5/100], Loss: 2.3744, Val Loss: 1.8246, Accuracy: 0.5390\n",
      "Epoch [6/100], Loss: 2.2267, Val Loss: 1.6898, Accuracy: 0.6109\n",
      "Epoch [7/100], Loss: 2.0640, Val Loss: 1.5473, Accuracy: 0.6121\n",
      "Epoch [8/100], Loss: 1.9914, Val Loss: 1.4272, Accuracy: 0.6627\n",
      "Epoch [9/100], Loss: 1.8705, Val Loss: 1.3506, Accuracy: 0.6608\n",
      "Epoch [10/100], Loss: 1.7848, Val Loss: 1.2822, Accuracy: 0.6802\n",
      "Epoch [11/100], Loss: 1.7158, Val Loss: 1.2019, Accuracy: 0.6983\n",
      "Epoch [12/100], Loss: 1.6616, Val Loss: 1.1598, Accuracy: 0.7046\n",
      "Epoch [13/100], Loss: 1.6104, Val Loss: 1.1303, Accuracy: 0.7064\n",
      "Epoch [14/100], Loss: 1.5917, Val Loss: 1.1305, Accuracy: 0.7164\n",
      "Epoch [15/100], Loss: 1.5540, Val Loss: 1.0906, Accuracy: 0.7171\n",
      "Epoch [16/100], Loss: 1.5065, Val Loss: 1.0706, Accuracy: 0.7177\n",
      "Epoch [17/100], Loss: 1.4586, Val Loss: 1.0300, Accuracy: 0.7370\n",
      "Epoch [18/100], Loss: 1.3887, Val Loss: 0.9828, Accuracy: 0.7527\n",
      "Epoch [19/100], Loss: 1.3473, Val Loss: 0.9492, Accuracy: 0.7495\n",
      "Epoch [20/100], Loss: 1.4491, Val Loss: 0.9979, Accuracy: 0.7370\n",
      "Epoch [21/100], Loss: 1.3724, Val Loss: 0.9554, Accuracy: 0.7489\n",
      "Epoch [22/100], Loss: 1.3222, Val Loss: 0.9380, Accuracy: 0.7508\n",
      "Epoch [23/100], Loss: 1.2692, Val Loss: 0.9263, Accuracy: 0.7620\n",
      "Epoch [24/100], Loss: 1.3086, Val Loss: 0.9075, Accuracy: 0.7508\n",
      "Epoch [25/100], Loss: 1.2974, Val Loss: 0.9027, Accuracy: 0.7502\n",
      "Epoch [26/100], Loss: 1.2581, Val Loss: 0.9046, Accuracy: 0.7589\n",
      "Epoch [27/100], Loss: 1.2123, Val Loss: 0.8668, Accuracy: 0.7701\n",
      "Epoch [28/100], Loss: 1.2218, Val Loss: 0.8736, Accuracy: 0.7670\n",
      "Epoch [29/100], Loss: 1.1834, Val Loss: 0.8537, Accuracy: 0.7633\n",
      "Epoch [30/100], Loss: 1.1866, Val Loss: 0.8608, Accuracy: 0.7701\n",
      "Epoch [31/100], Loss: 1.1702, Val Loss: 0.8454, Accuracy: 0.7658\n",
      "Epoch [32/100], Loss: 1.1243, Val Loss: 0.8284, Accuracy: 0.7776\n",
      "Epoch [33/100], Loss: 1.1066, Val Loss: 0.8158, Accuracy: 0.7776\n",
      "Epoch [34/100], Loss: 1.1231, Val Loss: 0.8352, Accuracy: 0.7708\n",
      "Epoch [35/100], Loss: 1.0566, Val Loss: 0.8141, Accuracy: 0.7839\n",
      "Epoch [36/100], Loss: 1.0989, Val Loss: 0.8164, Accuracy: 0.7783\n",
      "Epoch [37/100], Loss: 1.0921, Val Loss: 0.8122, Accuracy: 0.7839\n",
      "Epoch [38/100], Loss: 1.0918, Val Loss: 0.8019, Accuracy: 0.7770\n",
      "Epoch [39/100], Loss: 1.1160, Val Loss: 0.8052, Accuracy: 0.7776\n",
      "Epoch [40/100], Loss: 1.0799, Val Loss: 0.7938, Accuracy: 0.7751\n",
      "Epoch [41/100], Loss: 1.0744, Val Loss: 0.8131, Accuracy: 0.7720\n",
      "Epoch [42/100], Loss: 1.0396, Val Loss: 0.7942, Accuracy: 0.7801\n",
      "Epoch [43/100], Loss: 1.0401, Val Loss: 0.7659, Accuracy: 0.7989\n",
      "Epoch [44/100], Loss: 1.0348, Val Loss: 0.8222, Accuracy: 0.7808\n",
      "Epoch [45/100], Loss: 1.0228, Val Loss: 0.7956, Accuracy: 0.7845\n",
      "Epoch [46/100], Loss: 1.0112, Val Loss: 0.7931, Accuracy: 0.7858\n",
      "Epoch [47/100], Loss: 1.0097, Val Loss: 0.7768, Accuracy: 0.7920\n",
      "Epoch [48/100], Loss: 0.9591, Val Loss: 0.7796, Accuracy: 0.7833\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    vc_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = vc_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    vc_model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = vc_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "    \n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_character(audio_file):\n",
    "    vc_model.eval()\n",
    "    embedding = extract_voice_embeddings(audio_file)\n",
    "    embedding_scaled = scaler.transform([embedding])\n",
    "    embedding_tensor = torch.tensor(embedding_scaled, dtype=torch.float32).to(device)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = vc_model(embedding_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "    \n",
    "    return char_folder[pred.item()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddu\\anaconda3\\envs\\pytorch_audio\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lisa'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_character('characters/Lisa/27_audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(filename, duration, fs=16000):\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()  # Wait until the recording is finished\n",
    "    write(filename, fs, recording)\n",
    "    print(f\"Recording saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved to output.wav\n"
     ]
    }
   ],
   "source": [
    "record_audio('output.wav', duration=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddu\\anaconda3\\envs\\pytorch_audio\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Zhongli'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_character(\"output.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddu\\anaconda3\\envs\\pytorch_audio\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Zhongli'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_character(\"calvin.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
